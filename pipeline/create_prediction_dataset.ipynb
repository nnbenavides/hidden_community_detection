{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    x = np.load(filename, allow_pickle = True)\n",
    "    return x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embeddings_json(filename):\n",
    "    json_file = open(filename)\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    data = {int(k):v for k,v in json_data.items()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expects npy file to be a dict\n",
    "#embeddings = load_embeddings('data/node2vec_medium.npy')\n",
    "embeddings = load_embeddings_json('models/node2vec-dimension-512_lr-0.0500_seed-1234_epochs-250_numwalks-100_walklength-10_window-5_embedding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = len(embeddings[41393])\n",
    "print(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights_dict(filename):\n",
    "    weights = pd.read_csv(filename, header = None)\n",
    "    weights.columns = ['src', 'dst', 'weight']\n",
    "    \n",
    "    weights_dict = {}\n",
    "    for i in range(weights.shape[0]):\n",
    "        src = weights.iloc[i, 0]\n",
    "        dst = weights.iloc[i, 1]\n",
    "        weight = weights.iloc[i, 2]\n",
    "\n",
    "        weights_dict[(src, dst)] = weight\n",
    "        weights_dict[(dst, src)] = weight\n",
    "    return weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_dict = get_weights_dict('data/reddit_nodes_weighted_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load graph into networkx (weighted, undirected)\n",
    "def load_graph(filename):\n",
    "    df = pd.read_csv(filename, header=None, names=['source', 'target', 'weight'])\n",
    "    G = nx.from_pandas_edgelist(df, edge_attr='weight', create_using=nx.Graph())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = load_graph('data/reddit_nodes_weighted_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate positive examples of edges\n",
    "def get_positive_examples(G, embeddings, weights_dict):\n",
    "    pos_examples = []\n",
    "    for edge in G.edges():\n",
    "        src = edge[0]\n",
    "        dst = edge[1]\n",
    "        if src not in embeddings or dst not in embeddings:\n",
    "            continue\n",
    "        src_embedding = embeddings[src]\n",
    "        dst_embedding = embeddings[dst]\n",
    "        edge_vector = list(src_embedding) + list(dst_embedding) + [weights_dict[(edge[0], edge[1])]] # label = edge weight\n",
    "        pos_examples.append(edge_vector)\n",
    "    return pos_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate negative edges\n",
    "def get_negative_edges(G, num_examples = 1000000, attempts = 50000000, len_threshold = 5):\n",
    "    node_list = list(G.nodes())\n",
    "    edges_used = set()\n",
    "    for i in range(attempts):\n",
    "        if len(edges_used) == num_examples:\n",
    "            break\n",
    "        rnd_node_pair = random.choices(node_list, k = 2)\n",
    "        src = rnd_node_pair[0]\n",
    "        dst = rnd_node_pair[1]\n",
    "        if G.has_edge(src, dst):\n",
    "            continue\n",
    "        try:    \n",
    "            path_length = nx.shortest_path_length(G, source=src, target=dst, weight = None)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "        if(path_length) >= len_threshold:\n",
    "            edges_used.add((src, dst))\n",
    "    return list(edges_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neg_edges = get_negative_edges(G)\n",
    "#np.save('data/negative_sample_edges_large2.npy', neg_edges)\n",
    "#print(len(neg_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate negative examples\n",
    "def get_negative_examples(G, embeddings, negative_edges):\n",
    "    node_list = list(G.nodes())\n",
    "    neg_examples = []\n",
    "    for edge in negative_edges:\n",
    "        src = edge[0]\n",
    "        dst = edge[1]\n",
    "        if src not in embeddings or dst not in embeddings:\n",
    "            continue\n",
    "        src_embedding = embeddings[src]\n",
    "        dst_embedding = embeddings[dst]\n",
    "        edge_vector = list(src_embedding) + list(dst_embedding) + [0] # label = 0\n",
    "        neg_examples.append(edge_vector)\n",
    "    return neg_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_examples = get_positive_examples(G, embeddings, weights_dict)\n",
    "num_pos_examples = len(pos_examples)\n",
    "print(num_pos_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load negative edge samples - use pairs of nodes w/ no edge that are > 5 hops apart\n",
    "negative_edges = np.load('data/negative_sample_edges.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_examples = get_negative_examples(G, embeddings, negative_edges)\n",
    "num_neg_examples = len(neg_examples)\n",
    "print(num_neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_examples = pos_examples + neg_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/test dataframe from examples\n",
    "cols = ['src' + str(i) for i in range(embedding_dim)] + ['dst' + str(i) for i in range(embedding_dim)] + ['label']\n",
    "df = pd.DataFrame(all_examples, columns = cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/node2vec_512dim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate inference examples\n",
    "def get_inference_examples(G, embeddings, edges_used, num_examples = 500000, attempts = 1000000):\n",
    "    node_list = list(G.nodes())\n",
    "    inference_examples = []\n",
    "    for i in range(attempts):\n",
    "        if i % 100000 == 0:\n",
    "            print(i)\n",
    "        if len(inference_examples) == num_examples:\n",
    "            break\n",
    "        rnd_node_pair = random.choices(node_list, k = 2)\n",
    "        src = rnd_node_pair[0]\n",
    "        dst = rnd_node_pair[1]\n",
    "        if src not in embeddings or dst not in embeddings:\n",
    "            continue\n",
    "        if G.has_edge(src, dst):\n",
    "            continue\n",
    "        edge_tuple = (src, dst)\n",
    "        if edge_tuple not in edges_used:\n",
    "            src_embedding = embeddings[src]\n",
    "            dst_embedding = embeddings[dst]\n",
    "            edge_vector = [src, dst] + list(src_embedding) + list(dst_embedding)\n",
    "            inference_examples.append(edge_vector)\n",
    "    return inference_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_examples = get_inference_examples(G, embeddings, negative_edges)\n",
    "print(len(inference_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create inference dataframe from examples\n",
    "cols = ['src_id', 'dst_id'] + ['src' + str(i) for i in range(embedding_dim)] + ['dst' + str(i) for i in range(embedding_dim)]\n",
    "inference_df = pd.DataFrame(inference_examples, columns = cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inference_df.to_csv('data/rolx_inference_weighted.csv')\n",
    "inference_df.to_csv('data/node2vec_512dim_inference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "224env",
   "language": "python",
   "name": "224env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
